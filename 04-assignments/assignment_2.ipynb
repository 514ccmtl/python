{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHpGrEWbmHwP"
      },
      "source": [
        "# Assignment #2\n",
        "## Pandas and Visualization\n",
        "\n",
        "### Getting Data\n",
        "Select a dataset from [Toronto Open Data](https://open.toronto.ca/catalogue/) or another data portal of your choice, and download it. Some suggested datasets are linked below and additionally available for download in [the course repo /data folder](https://github.com/amfz/dsi-python-workshop/tree/main/data). A good dataset for this exercise will have a mix of data types.\n",
        "\n",
        "Some sugested datasets:\n",
        "* [TTC bus delays](https://open.toronto.ca/dataset/ttc-bus-delay-data/): Fewer columns, not well documented, some NaNs. Similar to data we've worked with in class. Recommend choosing a full year of data.\n",
        "* [Apartment building evaluations](https://open.toronto.ca/dataset/apartment-building-evaluation/): Lots of columns, well-documented, some NaNs.\n",
        "* [Daily shelter overnight service occupancy and capcity](https://open.toronto.ca/dataset/daily-shelter-overnight-service-occupancy-capacity/): The largest of the datasets suggested. Lots of columns, well-documented, more NaNs.\n",
        "\n",
        "### Metadata Review\n",
        "1. What organization publishes this dataset?\n",
        "2. How frequently is the dataset updated?\n",
        "3. What metadata is available (e.g., column names, data types, descriptions)?\n",
        "4. Is there documentation about who or what produces the data? About who collects it? Through what processes?\n",
        "5. Is there documentation about limitations of the data, such as possible sources of error or omission?\n",
        "6. Are there any restrictions concerning data access or use? (e.g.,registraton required or non-commercial use only)\n",
        "\n",
        "### Getting started\n",
        "1. Load the data to a single DataFrame.\n",
        "2. Profile the DataFrame.\n",
        "   * What are the column names?\n",
        "   * What are the dtypes when loaded? Do any not make sense?\n",
        "   * How many NaNs are in each column?\n",
        "   * What is the shape of the DataFrame?\n",
        "3. Generate some summary statistics for the data.\n",
        "   * For numeric columns: What are the max, min, mean, and median?\n",
        "   * For text columns: What is the most common value? How many unique values are there?\n",
        "   * Are there any statistics that seem unexpected?\n",
        "4. Rename one or more columns in the DataFrame.\n",
        "5. Select a single column and find its unique values.\n",
        "6. Select a single text/categorical column and find the counts of its values.\n",
        "7. Convert the data type of at least one of the columns. If all columns are typed correctly, convert one to `str` and back.\n",
        "8. Write the DataFrame to a different file format than the original.\n",
        "\n",
        "### More data wrangling, filtering\n",
        "1. Create a column derived from an existing one. Some possibilities:\n",
        "   * Bin a continuous variable\n",
        "   * Extract a date or time part (e.g. hour, month, day of week)\n",
        "   * Assign a value based on the value in another column (e.g. TTC line number based on line values in the subway delay data)\n",
        "   * Replace text in a column (e.g. replacing occurrences of \"Street\" with \"St.\")\n",
        "2. Remove one or more columns from the dataset.\n",
        "3. Extract a subset of columns and rows to a new DataFrame\n",
        "   * with the `.query()` method and column selecting `[[colnames]]`\n",
        "   * with `.loc[]`\n",
        "4. Investigate null values\n",
        "   * Create and describe a DataFrame containing records with NaNs in any column\n",
        "   * Create and describe a DataFrame containing records with NaNs in a subset of columns\n",
        "   * If it makes sense to drop records with NaNs in certain columns from the original DataFrame, do so.\n",
        "\n",
        "### Grouping and aggregating\n",
        "1. Use `groupby()` to split your data into groups based on one of the columns.\n",
        "2. Use `agg()` to apply multiple functions on different columns and create a summary table. Calculating group sums or standardizing data are two examples of possible functions that you can use.\n",
        "\n",
        "### Plot\n",
        "1. Plot two or more columns in your data using `matplotlib`, `seaborn`, or `plotly`. Make sure that your plot has labels, a title, a grid, and a legend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIcitxTKyZ2-"
      },
      "source": [
        "| Criteria                            | Pass Criteria                                                                                                                                                      | Fail Criteria                                                                                                             |\n",
        "|-------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n",
        "| **General Criteria**                |                                                                                                                                                                    |                                                                                                                           |\n",
        "| Code Execution                      | All code cells execute without errors.                                                                                                                             | Any code cell produces an error upon execution.                                                                           |\n",
        "| Code Quality                        | Code is well-organized, concise, and includes necessary comments for clarity.                                                                                      | Code is unorganized, verbose, or lacks necessary comments.                                                                 |\n",
        "| Data Handling                       | Proper handling, analysis, and visualization of the chosen dataset.                                                                                                | Data is not handled, analyzed, or visualized correctly.                                                                   |\n",
        "| Adherence to Instructions           | Follows all instructions and requirements as per the assignment.                                                                                                   | Misses or incorrectly implements one or more of the assignment requirements.                                              |\n",
        "| **Specific Criteria**               |                                                                                                                                                                    |                                                                                                                           |\n",
        "| Metadata Review         | Successfully reviews and documents metadata about the chosen dataset, including the publishing organization, update frequency, data types, and any limitations or restrictions. | Incomplete or incorrect review of the dataset's metadata. |\n",
        "| Getting Started           | Loads data into a DataFrame. Accurately profiles the DataFrame, including column names, data types, NaN counts, and DataFrame shape. Generates relevant summary statistics for the data. | Errors or inaccuracies in loading, profiling, or summarizing the data. |\n",
        "| More Data Wrangling, Filtering | Successfully creates a derived column. Appropriately removes one or more columns. Extracts a subset of columns and rows to a new DataFrame. Investigates and describes null values effectively. | Incomplete or incorrect implementation of data wrangling and filtering techniques. |\n",
        "| Grouping and Aggregating  | Correctly uses `groupby()` to split data into groups. Applies `agg()` function to perform multiple operations on different columns, creating a summary table. | Inaccurate or incomplete use of grouping and aggregation functions. |\n",
        "| Plot                   | Successfully plots two or more columns using `matplotlib`. Ensures the plot includes labels, a title, a grid, and a legend. | Incomplete or incorrect implementation of data visualization techniques. |\n",
        "| **Overall Assessment**              | Meets all the general and specific criteria, indicating a strong understanding of the assignment objectives. | Fails to meet one or more of the general or specific criteria, indicating a need for further learning or clarification. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSV4_oclrivw"
      },
      "source": [
        "## References\n",
        "\n",
        "### Data Sources\n",
        "- Open Data Toronto. _TTC Bus Delay Data_. https://open.toronto.ca/dataset/ttc-bus-delay-data/\n",
        "- Open Data Toronto. _Apartment Building Evaluation_. https://open.toronto.ca/dataset/apartment-building-evaluation/\n",
        "- Open Data Toronto. _Daily Shelter & Overnight Service Occupancy & Capacity_. https://open.toronto.ca/dataset/daily-shelter-overnight-service-occupancy-capacity/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
